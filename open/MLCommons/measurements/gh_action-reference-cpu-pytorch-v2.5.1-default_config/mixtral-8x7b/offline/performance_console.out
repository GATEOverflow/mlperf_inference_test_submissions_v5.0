Loading dataset...
Finished loading dataset.
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:18,  1.02s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:02<00:23,  1.38s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:03<00:21,  1.36s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:05<00:19,  1.29s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:06<00:17,  1.27s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:07<00:15,  1.22s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:08<00:14,  1.19s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:09<00:13,  1.18s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:11<00:13,  1.32s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:12<00:11,  1.25s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:13<00:10,  1.25s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:15<00:09,  1.30s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:16<00:08,  1.36s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:18<00:07,  1.46s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:21<00:07,  1.92s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:24<00:06,  2.18s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:25<00:03,  1.94s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:26<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:28<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:28<00:00,  1.48s/it]
INFO:Mixtral-8x7B-Instruct-v0.1-MAIN:Starting Benchmark run
/home/cmuser/venv/cm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.
  warnings.warn(
================================================
MLPerf Results Summary
================================================
SUT name : PySUT
Scenario : Offline
Mode     : PerformanceOnly
Samples per second: 0.000208239
Tokens per second: 0.0356089
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes

================================================
Additional Stats
================================================
Min latency (ns)                : 4802173583789
Max latency (ns)                : 4802173583789
Mean latency (ns)               : 4802173583789
50.00 percentile latency (ns)   : 4802173583789
90.00 percentile latency (ns)   : 4802173583789
95.00 percentile latency (ns)   : 4802173583789
97.00 percentile latency (ns)   : 4802173583789
99.00 percentile latency (ns)   : 4802173583789
99.90 percentile latency (ns)   : 4802173583789


================================================
Test Parameters Used
================================================
samples_per_query : 1
target_qps : 1
ttft_latency (ns): 2000000000
tpot_latency (ns): 200000000
max_async_queries : 1
min_duration (ms): 0
max_duration (ms): 0
min_query_count : 1
max_query_count : 1
qsl_rng_seed : 3066443479025735752
sample_index_rng_seed : 10688027786191513374
schedule_rng_seed : 14962580496156340209
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 1

No warnings encountered during test.

No errors encountered during test.
INFO:Mixtral-8x7B-Instruct-v0.1-MAIN:Run Completed!
INFO:Mixtral-8x7B-Instruct-v0.1-MAIN:Destroying SUT...
INFO:Mixtral-8x7B-Instruct-v0.1-MAIN:Destroying QSL...
Loaded model
Loaded tokenizer
IssueQuery started with 1 samples
IssueQuery done
Saving outputs to run_outputs/q0.pkl
Samples run: 1
	BatchMaker time: 0.014692068099975586
	Inference time: 4802.13894033432
	Postprocess time: 0.0197141170501709
	==== Total time: 4802.17334651947
